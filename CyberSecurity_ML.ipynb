{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder , MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Dropout\n",
    "from keras.optimizers import RMSprop , adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import flags\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier , VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score , roc_curve , auc , f1_score\n",
    "from sklearn.preprocessing import LabelEncoder , MinMaxScaler\n",
    "from sklearn.svm import SVC , LinearSVC\n",
    "\n",
    "import matplotlib . pyplot as plt\n",
    "plt.style.use('bmh')\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_integer (\"nb_epochs\", 20 , \"Number of epochs to train model\")\n",
    "flags.DEFINE_integer (\"batch_size\", 128 , \"Size of training batches\")\n",
    "flags.DEFINE_float (\"learning_rate\", 0.1 , \"Learning rate for training\")\n",
    "flags.DEFINE_integer (\"nb_classes\" , 5 , \"Number of classification classes\")\n",
    "flags.DEFINE_integer (\"source_samples\" , 10 , \"Nb of test set examples to attack\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StringType, IntegerType, StructType\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"cybersecurity\").getOrCreate()\n",
    "df_test = spark.read.csv('KDDTest+.csv',inferSchema=True,header=False).toDF(\"duration\", \"protocol\" , \"service\" , \"flag\", \"src_bytes\", \"dst_bytes\", \"land\", \"wrong_fragment\", \"urgent\", \n",
    "         \"hot\", \"num_failed_logins\", \"logged_in \", \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\", \n",
    "         \"num_file_creations\", \"num_shells\", \"num_access_files\",\"num_outbound_cmds \",\"is_host_login \", \"is_guest_login\",\n",
    "         \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\",\"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\", \n",
    "         \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\", \" dst_host_srv_count\", \"dst_host_same_srv_rate\", \n",
    "         \"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\", \" dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\",\n",
    "         \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"attack_type\", \"other\")\n",
    "df_train = spark.read.csv('KDDTrain+.csv',inferSchema=True,header=False).toDF(\"duration\", \"protocol\" , \"service\" , \"flag\", \"src_bytes\", \"dst_bytes\", \"land\", \"wrong_fragment\", \"urgent\", \n",
    "         \"hot\", \"num_failed_logins\", \"logged_in \", \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\", \n",
    "         \"num_file_creations\", \"num_shells\", \"num_access_files\",\"num_outbound_cmds \",\"is_host_login \", \"is_guest_login\",\n",
    "         \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\",\"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\", \n",
    "         \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\", \" dst_host_srv_count\", \"dst_host_same_srv_rate\", \n",
    "         \"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\", \" dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\",\n",
    "         \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"attack_type\", \"other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df_train.union(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na.replace([\"neptune\", \"back\", \"land\", \"pod\", \"smurf\", \"teardrop\", \"mailbomb\", \"processtable\", \"udpstorm\", \"apache2\", \"worm\"], \"dos\", \"attack_type\")\n",
    "\n",
    "df = df.na.replace([\"buffer_overflow \", \"loadmodule\", \"perl\", \"rootkit\", \"sqlattack\", \"xterm\", \"ps\"], \"u2r\", \"attack_type\")\n",
    "\n",
    "df = df.na.replace([\"ftp_write\", \"guess_passwd\", \"imap\", \"multihop\", \"phf\", \"spy\", \"warezclient\", \"warezmaster\", \"xlock\", \"xsnoop\", \"snmpgetattack\", \"httptunnel\", \"snmpguess\", \"sendmail\", \"named\"], \"r2l\", \"attack_type\")\n",
    "\n",
    "df = df.na.replace([\"satan \", \"ipsweep\", \"nmap\", \"portsweep\", \"saint\", \"mscan\"], \"probe\", \"attack_type\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.attack_type == \"u2r\"].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.select(df.columns[:-2])\n",
    "y = df.select(df.columns[41])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringIndexer = StringIndexer(inputCol=\"attack_type\", outputCol=\"attackIndex\")\n",
    "model = stringIndexer.fit(y)\n",
    "indexed = model.transform(y)\n",
    "\n",
    "encoder = OneHotEncoder(inputCol=\"attackIndex\", outputCol=\"attack_type_Vec\")\n",
    "encoded = encoder.transform(indexed)\n",
    "encoded.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = encoded.select(encoded.columns[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
